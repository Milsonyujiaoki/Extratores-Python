# -*- coding: utf-8 -*-
"""
ExtraÃ§Ã£o usando OpenAI Vision API ASSÃNCRONA - Para PDFs complexos ou com formataÃ§Ã£o especial
Biblioteca: openai, pdf2image, asyncio
InstalaÃ§Ã£o: pip install openai pdf2image pillow
ConfiguraÃ§Ã£o: Definir OPENAI_API_KEY como variÃ¡vel de ambiente
"""
from calendar import c
import os
from shlex import join
import sys
import base64
from pdf2image import convert_from_path
import tempfile
import asyncio
from functools import partial
import logging
import time
from pathlib import Path

# Configurar encoding para Windows
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')
import json
from datetime import datetime

# ConfiguraÃ§Ã£o do sistema de logging estruturado
class StructuredLogger:
    def __init__(self, project_name="openai_vision", log_dir="logs"):
        
        self.project_name = project_name
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True)
        
        # Configurar formatador estruturado
        log_format = '%(asctime)s | %(levelname)8s | %(name)15s | %(message)s'
        date_format = '%Y-%m-%d %H:%M:%S'
        
        # Logger principal
        self.logger = logging.getLogger(f'openai_vision_{project_name}')
        self.logger.setLevel(logging.DEBUG)
        
        # Remover handlers existentes para evitar duplicaÃ§Ã£o
        for handler in self.logger.handlers[:]:
            self.logger.removeHandler(handler)
        
        # Handler para arquivo de log geral
        log_file = self.log_dir / f"{project_name}_extraction_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setLevel(logging.DEBUG)
        file_handler.setFormatter(logging.Formatter(log_format, date_format))
        
        # Handler para console com cores
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        console_handler.setFormatter(logging.Formatter(log_format, date_format))
        
        self.logger.addHandler(console_handler)
        
        # Loggers especializados por fase
        self.phases = {
            'INIT': logging.getLogger(f'openai_vision_{project_name}.init'),
            'PDF_SCAN': logging.getLogger(f'openai_vision_{project_name}.pdf_scan'),
            'PDF_CONV': logging.getLogger(f'openai_vision_{project_name}.pdf_convert'),
            'API_CALL': logging.getLogger(f'openai_vision_{project_name}.api_call'),
            'TEXT_PROC': logging.getLogger(f'openai_vision_{project_name}.text_process'),
            'FILE_SAVE': logging.getLogger(f'openai_vision_{project_name}.file_save'),
            'STATS': logging.getLogger(f'openai_vision_{project_name}.statistics')
        }
        
        # Configurar todos os loggers de fase (evita duplicidade de handlers)
        for phase_logger in self.phases.values():
            phase_logger.setLevel(logging.DEBUG)
            if not phase_logger.handlers:
                phase_logger.addHandler(file_handler)
                phase_logger.addHandler(console_handler)
        
        self.start_time = time.time()
        self.phase_times = {}
        
        # Log inicial
        self.logger.info("="*80)
        self.logger.info(f"ðŸš€ SISTEMA DE LOGGING INICIADO - {project_name.upper()}")
        self.logger.info(f"ðŸ“ Log salvo em: {log_file}")
        self.logger.info("="*80)
    
    def start_phase(self, phase_name, description=""):
        """Inicia uma nova fase de processamento"""
        if phase_name in self.phase_times:
            # Finaliza fase anterior se ainda estiver ativa
            self.end_phase(phase_name)
        
        self.phase_times[phase_name] = time.time()
        phase_logger = self.phases.get(phase_name, self.logger)
        
        message = f"ðŸ”„ INICIANDO FASE: {phase_name}"
        if description:
            message += f" - {description}"
        
        phase_logger.info("â”€" * 60)
        phase_logger.info(message)
        phase_logger.info("â”€" * 60)
    
    def end_phase(self, phase_name, success=True):
        """Finaliza uma fase de processamento"""
        if phase_name not in self.phase_times:
            return
        
        duration = time.time() - self.phase_times[phase_name]
        del self.phase_times[phase_name]
        
        phase_logger = self.phases.get(phase_name, self.logger)
        status = "âœ… CONCLUÃDA" if success else "âŒ FALHOU"
        
        phase_logger.info(f"{status} FASE: {phase_name} ({duration:.2f}s)")
        phase_logger.info("â”€" * 60)
    
    def log_progress(self, phase_name, current, total, item_name="", extra_info=""):
        """Log de progresso durante uma fase"""
        phase_logger = self.phases.get(phase_name, self.logger)
        percentage = (current / total * 100) if total > 0 else 0
        
        progress_bar = "â–ˆ" * int(percentage / 5) + "â–‘" * (20 - int(percentage / 5))
        message = f"ðŸ“Š [{progress_bar}] {current}/{total} ({percentage:.1f}%)"
        
        if item_name:
            message += f" - {item_name}"
        if extra_info:
            message += f" | {extra_info}"
        
        phase_logger.info(message)
    
    def log_api_call(self, page_num, total_pages, status="enviando", response_size=0, error=None):
        """Log especÃ­fico para chamadas da API"""
        api_logger = self.phases['API_CALL']
        
        if status == "enviando":
            api_logger.info(f"ðŸ¤– API Call [{page_num}/{total_pages}] - Enviando pÃ¡gina para OpenAI Vision...")
        elif status == "sucesso":
            api_logger.info(f"âœ… API Call [{page_num}/{total_pages}] - Resposta recebida: {response_size} caracteres")
        elif status == "erro":
            api_logger.error(f"âŒ API Call [{page_num}/{total_pages}] - ERRO: {error}")
    
    def log_file_operation(self, operation, file_path, success=True, size=0, error=None):
        """Log para operaÃ§Ãµes de arquivo"""
        file_logger = self.phases['FILE_SAVE']
        
        if operation == "save" and success:
            file_logger.info(f"ðŸ’¾ Arquivo salvo: {Path(file_path).name} ({size} bytes)")
        elif operation == "save" and not success:
            file_logger.error(f"âŒ Erro ao salvar: {Path(file_path).name} - {error}")
        elif operation == "load":
            file_logger.info(f"ðŸ“‚ Carregando: {Path(file_path).name}")
    
    def log_statistics(self, stats_dict):
        """Log de estatÃ­sticas finais"""
        stats_logger = self.phases['STATS']
        stats_logger.info("ðŸ“Š ESTATÃSTICAS FINAIS:")
        
        for key, value in stats_dict.items():
            stats_logger.info(f"   {key}: {value}")
    
    def get_total_runtime(self):
        """Retorna o tempo total de execuÃ§Ã£o"""
        return time.time() - self.start_time

# InstÃ¢ncia global do logger
logger_instance = None

def get_logger(project_name="default"):
    """ObtÃ©m a instÃ¢ncia do logger estruturado"""
    global logger_instance
    if logger_instance is None:
        logger_instance = StructuredLogger(project_name)
    return logger_instance

try:
    from openai import AsyncOpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

import json

import json

import re
import json

def salvar_json_removendo_cabecalho_rodape(results_consolidado_json, output_path, logger=None):
    try:
        # Junta todas as strings da lista em uma sÃ³, se necessÃ¡rio
        if isinstance(results_consolidado_json, list):
            joined = "\n".join(results_consolidado_json)
        elif isinstance(results_consolidado_json, str):
            joined = results_consolidado_json
        else:
            raise TypeError("âŒ ConteÃºdo inesperado: precisa ser lista ou string.")

        # Divide em linhas
        linhas = joined.strip().splitlines()

        # Remove as 3 primeiras e as 3 Ãºltimas
        linhas_limpa = linhas[3:-3]

        # Junta de novo em um Ãºnico JSON
        json_str = "\n".join(linhas_limpa)

        # Valida o JSON
        parsed_json = json.loads(json_str)

        # Salva
        output_path = output_path if output_path.endswith('.json') else output_path + ".json"
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(parsed_json, f, ensure_ascii=False, indent=4)

        if logger:
            logger.phases['FILE_SAVE'].info("âœ… JSON salvo com sucesso.")
            logger.end_phase('FILE_SAVE', True)
        else:
            print("âœ… JSON salvo com sucesso.")

    except Exception as e:
        msg = f"âŒ Erro ao salvar JSON: {e}"
        if logger:
            logger.phases['FILE_SAVE'].error(msg)
            logger.end_phase('FILE_SAVE', False)
        else:
            print(msg)

async def requisicao_async(client, extracted_text, logger=None):
    """Faz uma requisiÃ§Ã£o assÃ­ncrona para a API OpenAI"""
    try:
        if logger:
            logger.phases['API_CALL'].info("ðŸ¤– Enviando texto extraÃ­do para OpenAI Vision API...")
        else:
            print("ðŸ¤– Enviando texto extraÃ­do para OpenAI Vision API...")
        
        response = await client.chat.completions.create(
            model="gpt-4.1-nano",
             messages=[
                {"role": "system", "content": "VocÃª Ã© um assistente especializado na consolidaÃ§Ã£o de dados estruturados."},
                {"role": "user", "content": "Consolide os dados estruturados extraÃ­dos em um formato JSON pelas paginas, ai em cada pagina tera suas datas(vencimento, pagamento,socilitacao, etc), valores monetarios."},
                {"role": "assistant", "content": "Claro! Vou consolidar os dados estruturados em um formato JSON organizado."},
                {
                    "role": "user",
                    "content": f"{extracted_text}"
                }
            ],
            temperature=0.1
        )
        extracted_json = response.choices[0].message.content

        if logger:
            logger.phases['API_CALL'].info("âœ… Resposta recebida da API.")
        else:
            print("âœ… Resposta recebida da API.")

        return extracted_json

    except Exception as e:
        error_msg = f"âŒ Erro na requisiÃ§Ã£o Ã  API: {e}"
        if logger:
            logger.phases['API_CALL'].error(error_msg)
        else:
            print(error_msg)
        return None

def encode_image_to_base64(image_path):
    """Converte imagem para base64 para enviar Ã  API"""
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')

async def process_page_async(client, page_image_data, page_num, total_pages, logger=None):
    """Processa uma pÃ¡gina de forma assÃ­ncrona"""
    try:
        if logger:
            logger.log_api_call(page_num, total_pages, "enviando")
        else:
            print(f"   ðŸ¤– [{page_num}/{total_pages}] Enviando para OpenAI Vision API...")
        
        response = await client.chat.completions.create(
            model="gpt-4.1-nano",
            messages=[
                {"role": "system", "content": "VocÃª Ã© um assistente extrator de informaÃ§Ãµes de boletos, comprovantes de pagamento, etc."},
                {"role": "system", "content": (
                            "VocÃª Ã© um assistente jurÃ­dico especializado na extraÃ§Ã£o de informaÃ§Ãµes "
                            "de documentos diversos como contratos, boletos, notas fiscais e prints. ")},
                {"role": "user",   "content": "VocÃª irÃ¡ analisar cada pÃ¡gina do documento e extrair informaÃ§Ãµes estruturadas. Arquivos como boletos podem conter informaÃ§Ãµes relevantes como data de vencimento, valor de pagamento, data de processamento, descriÃ§Ã£o, deduÃ§Ãµes, multas, juros, data do documento, nosso numero, nÃºmero do documento, data de emissÃ£o, data de processamento, data de vencimento, valor do documento, valor pago, valor da multa, valor dos juros, valor total a pagar, valor do desconto, data do desconto, data de compensaÃ§Ã£o, data de baixa. Em arquivos como comprovantes de pagamento, extratos bancÃ¡rios, etc., extraia informaÃ§Ãµes como data de transaÃ§Ã£o, valor, descriÃ§Ã£o, saldo, data de credito, data de solicitaÃ§Ã£o, desconto, juros."},
                {"role": "assistant", "content": "Claro! Pode me fornecer o texto ou imagem?"},
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": """Extraia informaÃ§Ãµes estruturadas desta pÃ¡gina:
                                    Organize as informaÃ§Ãµes de forma clara e estruturada
                                    - Tipo de documento (contrato, nota fiscal, relatÃ³rio, boleto, print, tabela, tela de software)
                                    - Valores monetÃ¡rios detalhados, incluindo:
                                        - Valor do documento
                                        - Valor pago
                                        - Valor da multa
                                        - Valor dos juros
                                        - Valor total a pagar
                                        - Valor do desconto
                                    - Datas encontradas(detalhes como vencimento, emissÃ£o, processamento, pagamento, solicitaÃ§Ã£o, compensaÃ§Ã£o, baixa):
                                        - Data do desconto
                                        - Data de compensaÃ§Ã£o
                                        - Data de baixa
                                        - Data de vencimento
                                        - Data de emissÃ£o
                                        - Data de processamento
                                        - Data de solicitaÃ§Ã£o
                                        - Data de crÃ©dito
                                        - Data de Pagamento
                                    - Nomes de pessoas/empresas
                                    - NÃºmeros de documentos (nosso nÃºmero, nÃºmero do documento)
                                    - Tabelas completas 
                                    
                                    """
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/png;base64,{page_image_data}"
                            }
                        }
                    ]
                }
            ],
            temperature=0.1
        )
        
        page_text = response.choices[0].message.content
        response_size = len(page_text) if page_text else 0
        
        if logger:
            logger.log_api_call(page_num, total_pages, "sucesso", response_size)
        else:
            print(f"   âœ… [{page_num}/{total_pages}] Resposta recebida: {response_size} caracteres")
        
        return page_num, page_text
        
    except Exception as e:
        if logger:
            logger.log_api_call(page_num, total_pages, "erro", error=str(e))
        else:
            print(f"   âŒ [{page_num}/{total_pages}] Erro: {e}")
        return page_num, f"[ERRO NA API OPENAI: {e}]"

async def extract_text_openai_vision_async(pdf_path, txt_path, json_output_txt, json_output, api_key, max_concurrent=40, logger=None):
    """
    Extrai texto usando OpenAI Vision API de forma ASSÃNCRONA
    """
    if not OPENAI_AVAILABLE:
        error_msg = "âŒ Biblioteca OpenAI nÃ£o estÃ¡ instalada. Execute: pip install openai"
        if logger:
            logger.phases['INIT'].error(error_msg)
        else:
            print(error_msg)
        with open(txt_path, "w", encoding="utf-8") as f:
            f.write(error_msg)
        return False
    
    # ConfiguraÃ§Ã£o da API
    if api_key is None:
        api_key = os.environ.get('OPENAI_API_KEY', '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')
    
    if not api_key:
        error_msg = "âŒ OPENAI_API_KEY nÃ£o configurada. Defina a variÃ¡vel de ambiente."
        if logger:
            logger.phases['INIT'].error(error_msg)
        else:
            print(error_msg)
        with open(txt_path, "w", encoding="utf-8") as f:
            f.write(error_msg + "\n")
            f.write("Configure: set OPENAI_API_KEY=sua_chave_aqui\n")
        return False
    
    try:
        # Fase de inicializaÃ§Ã£o
        if logger:
            logger.start_phase('INIT', f"Configurando extraÃ§Ã£o para {os.path.basename(pdf_path)}")
            logger.phases['INIT'].info(f"ðŸ”‘ API Key configurada: {api_key[:20]}...")
            logger.phases['INIT'].info(f"âš¡ MÃ¡ximo de requisiÃ§Ãµes simultÃ¢neas: {max_concurrent}")
        
        client = AsyncOpenAI(api_key=api_key)
        
        if not logger:
            print(f"ðŸ¤– Iniciando extraÃ§Ã£o OpenAI Vision ASSÃNCRONA para {os.path.basename(pdf_path)}...")
            print(f"ðŸ”‘ API Key configurada: {api_key[:20]}...")
            print(f"âš¡ MÃ¡ximo de requisiÃ§Ãµes simultÃ¢neas: {max_concurrent}")
        
        # Fase de conversÃ£o PDF
        if logger:
            logger.end_phase('INIT', True)
            logger.start_phase('PDF_CONV', "Convertendo PDF para imagens")
        
        with tempfile.TemporaryDirectory() as temp_dir:
            if not logger:
                print("ðŸ“„ Convertendo PDF para imagens...")
            
            try:
                pages = convert_from_path(pdf_path, dpi=300, output_folder=temp_dir)
                if logger:
                    logger.phases['PDF_CONV'].info(f"âœ… PDF convertido: {len(pages)} pÃ¡ginas detectadas")
                else:
                    print(f"âœ… PDF convertido: {len(pages)} pÃ¡ginas detectadas")
            except Exception as e:
                if logger:
                    logger.phases['PDF_CONV'].error(f"âŒ Erro na conversÃ£o PDF: {e}")
                    logger.end_phase('PDF_CONV', False)
                else:
                    print(f"âŒ Erro na conversÃ£o PDF: {e}")
                raise
            
            # Fase de preparaÃ§Ã£o das pÃ¡ginas
            if logger:
                logger.end_phase('PDF_CONV', True)
                logger.start_phase('TEXT_PROC', "Preparando pÃ¡ginas para processamento")
            
            page_data = []
            
            if not logger:
                print(f"ðŸ”„ Preparando {len(pages)} pÃ¡ginas para processamento paralelo...")
            
            for i, page in enumerate(pages, 1):
                page_path = os.path.join(temp_dir, f"page_{i}.png")
                page.save(page_path, "PNG")
                
                # Verifica tamanho da imagem
                img_size = os.path.getsize(page_path) / 1024  # KB
                
                if logger:
                    logger.log_progress('TEXT_PROC', i, len(pages), f"PÃ¡gina {i}", f"{img_size:.1f} KB")
                else:
                    print(f"   ðŸ“Š PÃ¡gina {i}: {img_size:.1f} KB")
                
                # Codifica para base64
                base64_image = encode_image_to_base64(page_path)
                page_data.append((i, base64_image))
            
            # Fase de processamento API
            if logger:
                logger.end_phase('TEXT_PROC', True)
                logger.start_phase('API_CALL', f"Processamento paralelo de {len(pages)} pÃ¡ginas")
            else:
                print(f"ðŸš€ Iniciando processamento PARALELO de {len(pages)} pÃ¡ginas...")
            
            # Cria semÃ¡foro para limitar requisiÃ§Ãµes simultÃ¢neas
            semaphore = asyncio.Semaphore(max_concurrent)
            
            async def process_with_semaphore(page_num, image_data):
                async with semaphore:
                    return await process_page_async(client, image_data, page_num, len(pages), logger)
            
            # Processa todas as pÃ¡ginas em paralelo
            tasks = [process_with_semaphore(page_num, image_data) for page_num, image_data in page_data]
            results = await asyncio.gather(*tasks)
            
            # Fase de salvamento
            if logger:
                logger.end_phase('API_CALL', True)
                logger.start_phase('FILE_SAVE', "Organizando e salvando resultados")
            
            # Organiza resultados
            extracted_text = []
            extracted_json = []
            extracted_text.append("=== EXTRAÃ‡ÃƒO OPENAI VISION API (ASSÃNCRONA) ===\n")
            extracted_text.append(f"Arquivo: {os.path.basename(pdf_path)}\n")
            extracted_text.append(f"Data/Hora: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\n")
            extracted_text.append(f"PÃ¡ginas processadas: {len(pages)}\n")
            extracted_text.append(f"Processamento: PARALELO ({max_concurrent} requisiÃ§Ãµes simultÃ¢neas)\n")
            extracted_text.append("="*50 + "\n\n")
            
            # Ordena resultados por nÃºmero da pÃ¡gina
            results.sort(key=lambda x: x[0])
            
            for page_num, page_text in results:
                if page_text and page_text.strip() and not page_text.startswith("[ERRO"):
                    extracted_text.append(f"=== PÃGINA {page_num} ===\n")
                    extracted_text.append(page_text.strip())
                    extracted_text.append(f"\n\n{'='*30}\n\n")
                    if logger:
                        logger.phases['FILE_SAVE'].info(f"ðŸ“ PÃ¡gina {page_num}: Texto extraÃ­do com sucesso")
                    else:
                        print(f"   ðŸ“ PÃ¡gina {page_num}: Texto extraÃ­do com sucesso")
                else:
                    extracted_text.append(f"=== PÃGINA {page_num} ===\n")
                    extracted_text.append(page_text if page_text else "[PÃGINA EM BRANCO OU SEM TEXTO DETECTADO]")
                    extracted_text.append(f"\n\n{'='*30}\n\n")
                    if logger:
                        logger.phases['FILE_SAVE'].warning(f"âš ï¸ PÃ¡gina {page_num}: {page_text if page_text and page_text.startswith('[ERRO') else 'Sem texto detectado'}")
                    else:
                        print(f"   âš ï¸ PÃ¡gina {page_num}: {page_text if page_text and page_text.startswith('[ERRO') else 'Sem texto detectado'}")
                        
        # Consolida resultados em JSON
        if logger:
            logger.phases['FILE_SAVE'].info("ðŸ”„ Consolidando resultados em JSON...")
            logger.phases['FILE_SAVE'].info(f"ðŸ’¾ Salvando resultado em: {json_output_txt}")
            logger.phases['FILE_SAVE'].info(f"ðŸ’¾ Salvando resultado em: {json_output}")
        else:
            print(f" Salvando resultados em {json_output_txt}")
            print(f" Salvando resultados em {json_output}")
        
        """async def requisicao_async_with_semaphore(client, extracted_text, logger=None):
            async with semaphore:
                return await requisicao_async(client, "".join(extracted_text), logger)


        tasks = [requisicao_async_with_semaphore(client, "".join(extracted_text), logger) for _ in range(len(pages))]
        results = await asyncio.gather(*tasks)"""
        results = await requisicao_async(client, "".join(extracted_text), logger)
        extracted_json.append(results)

        # Salva resultado
        if logger:
            logger.phases['FILE_SAVE'].info(f"ðŸ’¾ Salvando resultado em: {txt_path}")
        else:
            print(f"ðŸ’¾ Salvando resultado em: {txt_path}")
        
        with open(txt_path, "w", encoding="utf-8") as f:
            f.write("".join(extracted_text))
            
        with open(json_output_txt, "w", encoding="utf-8") as f:
            f.write("".join(extracted_json))
        
        with open(json_output, "w", encoding="utf-8") as f:
            f.write("".join(extracted_json))
        
        # Verifica arquivo salvo
        if os.path.exists(txt_path):
            file_size = os.path.getsize(txt_path)
            if logger:
                logger.log_file_operation("save", txt_path, True, file_size)
                logger.end_phase('FILE_SAVE', True)
            else:
                print(f"âœ… OpenAI Vision ASSÃNCRONA: Arquivo salvo ({file_size} bytes)")
        else:
            if logger:
                logger.log_file_operation("save", txt_path, False, error="Arquivo nÃ£o foi criado")
                logger.end_phase('FILE_SAVE', False)
            else:
                print(f"âŒ Erro: Arquivo nÃ£o foi criado")
            return False
        
        return True
        
    except Exception as e:
        if logger:
            logger.phases['API_CALL'].error(f"âŒ Erro na OpenAI Vision API ASSÃNCRONA: {e}")
            # Finaliza todas as fases ativas
            for phase in logger.phase_times.keys():
                logger.end_phase(phase, False)
        else:
            print(f"âŒ Erro na OpenAI Vision API ASSÃNCRONA: {e}")
        
        with open(txt_path, "w", encoding="utf-8") as f:
            f.write(f"ERRO NA OPENAI VISION API ASSÃNCRONA: {e}\n")
            f.write("Verifique se a chave da API estÃ¡ configurada corretamente.\n")
        return False

def extract_text_openai_vision(pdf_path, txt_path, json_output_txt, json_output, api_key='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', logger=None):
    """Wrapper sÃ­ncrono para a funÃ§Ã£o assÃ­ncrona"""
    return asyncio.run(extract_text_openai_vision_async(pdf_path, txt_path, json_output_txt, json_output, api_key, max_concurrent=40, logger=logger))

def extract_structured_openai_vision(pdf_path, output_path, output_txt, output_JSON, api_key=None, logger=None):
    """
    ExtraÃ§Ã£o estruturada usando OpenAI Vision com prompts especializados
    """
    if not OPENAI_AVAILABLE:
        return False
    
    if api_key is None:
        api_key = os.environ.get('OPENAI_API_KEY', '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')
    
    if not api_key:
        return False
    
    try:
        # Fase de anÃ¡lise estruturada
        if logger:
            logger.start_phase('TEXT_PROC', f"AnÃ¡lise estruturada de {os.path.basename(pdf_path)}")
        
        # Usando cliente sÃ­ncrono para extraÃ§Ã£o estruturada (menos pÃ¡ginas, mais detalhada)
        from openai import OpenAI
        client = OpenAI(api_key=api_key)
        
        if logger:
            logger.phases['TEXT_PROC'].info(f"ðŸ§  Iniciando extraÃ§Ã£o estruturada...")
        else:
            print(f"ðŸ§  ExtraÃ§Ã£o estruturada OpenAI Vision para {os.path.basename(pdf_path)}...")
        
        with tempfile.TemporaryDirectory() as temp_dir:
            pages = convert_from_path(pdf_path, dpi=300, output_folder=temp_dir)
            
            if logger:
                logger.phases['TEXT_PROC'].info(f"ðŸ“„ Convertido: {len(pages)} pÃ¡ginas para anÃ¡lise estruturada")
            
            results = []
            #results_analise = []
            results_consolidador_json = []
            results.append("=== ANÃLISE ESTRUTURADA OPENAI VISION ===\n")
            results.append(f"Arquivo: {os.path.basename(pdf_path)}\n")
            results.append(f"Data/Hora: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\n")
            results.append("="*50 + "\n\n")
            
            # Analisa todo o documento primeiro
            if len(pages) > 0:
                if logger:
                    logger.log_progress('TEXT_PROC', 1, len(pages) + 1, "AnÃ¡lise geral do documento", "Primeira pÃ¡gina")
                
                '''# Extrai dados estruturados de cada pÃ¡gina
            for i, page in enumerate(pages, 1):
                page_path = os.path.join(temp_dir, f"page_{i}.png")
                page.save(page_path, "PNG")
                base64_image = encode_image_to_base64(page_path)
                
                response = client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[
                        {
                            "role": "user",
                            "content": [
                                {
                                    "type": "text",
                                    "text": """Analise este documento e identifique:
                                    1. Tipo de documento (boleto, nota fiscal, comprovante pagamento, etc.)
                                    2. InformaÃ§Ãµes-chave visÃ­veis
                                    3. PossÃ­veis tabelas ou listas
                                    4. Valores monetÃ¡rios, datas, nomes, nÃºmeros de documentos, etc.

                                    Seja detalhado na anÃ¡lise."""
                                },
                                {
                                    "type": "image_url",
                                    "image_url": {
                                        "url": f"data:image/png;base64,{base64_image}"
                                    }
                                }
                            ]
                        }
                    ],
                    temperature=0.2
                )
                
                analysis = response.choices[0].message.content
                results_analise.append("=== ANÃLISE GERAL DO DOCUMENTO ===\n")
                results_analise.append(analysis)
                results_analise.append(f"\n\n{'='*40}\n\n")
                
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                        {"role": "system", "content": "VocÃª Ã© um assistente especializado na analise, entendimento, extraÃ§Ã£o de informaÃ§Ãµes e estruturaÃ§Ã£o de documentos."},

                        {"role": "user", "content": "VocÃª irÃ¡ analisar o documento e estruturar as informaÃ§Ãµes de maneira clara e organizada."},
                        {"role": "user", "content": f"{results_analise}"}
                    ],
                    temperature=0.2
                )
            analysis_result = response.choices[0].message.content
            results.append(analysis_result)
            results.append(f"\n\n{'='*40}\n\n")'''
                

            # Extrai dados estruturados de cada pÃ¡gina
            for i, page in enumerate(pages, 1):
                if logger:
                    logger.log_progress('TEXT_PROC', i + 1, len(pages) + 1, f"PÃ¡gina {i}", "Dados estruturados")
                
                page_path = os.path.join(temp_dir, f"page_{i}.png")
                page.save(page_path, "PNG")
                base64_image = encode_image_to_base64(page_path)
                
                response = client.chat.completions.create(
                    model="gpt-4.1-nano",
                    messages=[
                        {"role": "system", "content": "VocÃª Ã© um assistente extrator de informaÃ§Ãµes de boletos, comprovantes de pagamento, etc."},
                        {"role": "system", "content": (
                            "VocÃª Ã© um assistente jurÃ­dico especializado na extraÃ§Ã£o de informaÃ§Ãµes "
                            "de documentos diversos como contratos, boletos, notas fiscais e prints. "
                        )},
                        {"role": "user",   "content": "VocÃª irÃ¡ analisar cada pÃ¡gina do documento e extrair informaÃ§Ãµes estruturadas. Arquivos como boletos podem conter informaÃ§Ãµes relevantes como data de vencimento, valor de pagamento, data de processamento, descriÃ§Ã£o, deduÃ§Ãµes, multas, juros, data do documento, nosso numero, nÃºmero do documento, data de emissÃ£o, data de processamento, data de vencimento, valor do documento, valor pago, valor da multa, valor dos juros, valor total a pagar, valor do desconto, data do desconto, data de compensaÃ§Ã£o, data de baixa. Em arquivos como comprovantes de pagamento, extratos bancÃ¡rios, etc., extraia informaÃ§Ãµes como data de transaÃ§Ã£o, valor, descriÃ§Ã£o, saldo, data de credito, data de solicitaÃ§Ã£o, desconto, juros."},
                        {"role": "assistant", "content": "Claro! Pode me fornecer o texto ou imagem?"},
                        {
                            "role": "user",
                            "content": [
                                {
                                    "type": "text",
                                    "text": """Extraia informaÃ§Ãµes estruturadas desta pÃ¡gina:
                                    Organize as informaÃ§Ãµes de forma clara e estruturada
                                    - Tipo de documento (contrato, nota fiscal, relatÃ³rio, boleto, print, tabela, tela de software)
                                    - Valores monetÃ¡rios detalhados, incluindo:
                                        - Valor do documento
                                        - Valor pago
                                        - Valor da multa
                                        - Valor dos juros
                                        - Valor total a pagar
                                        - Valor do desconto
                                    - Datas encontradas(detalhes como vencimento, emissÃ£o, processamento, pagamento, solicitaÃ§Ã£o, compensaÃ§Ã£o, baixa):
                                        - Data do desconto
                                        - Data de compensaÃ§Ã£o
                                        - Data de baixa
                                        - Data de vencimento
                                        - Data de emissÃ£o
                                        - Data de processamento
                                        - Data de solicitaÃ§Ã£o
                                        - Data de crÃ©dito
                                        - Data de Pagamento
                                    - Nomes de pessoas/empresas
                                    - NÃºmeros de documentos (nosso nÃºmero, nÃºmero do documento)
                                    - Tabelas completas 
                                    
                                    """
                                },
                                {
                                    "type": "image_url",
                                    "image_url": {
                                        "url": f"data:image/png;base64,{base64_image}"
                                    }
                                }
                            ]
                        }
                    ],
                    temperature=0.2
                )
                
                structured_data = response.choices[0].message.content
                results.append(f"=== DADOS ESTRUTURADOS - PÃGINA {i} ===\n")
                results.append(structured_data)
                results.append(f"\n\n{'='*40}\n\n")


        response = client.chat.completions.create(
            model="gpt-4.1-nano-2025-04-14",
            messages=[
                {"role": "system", "content": "VocÃª Ã© um assistente especializado na consolidaÃ§Ã£o de dados estruturados."},
                {"role": "user", "content": "Consolide os dados estruturados extraÃ­dos em um formato JSON pelas paginas, ai em cada pagina tera suas datas(vencimento, pagamento,socilitacao, etc), valores monetarios."},
                {"role": "assistant", "content": "Claro! Vou consolidar os dados estruturados em um formato JSON organizado."},
                {
                    "role": "user",
                    "content": f"{results}"
                }
            ],
            temperature=0.2
        )
        consolidated_data = response.choices[0].message.content
        results_consolidador_json.append(consolidated_data)
        
        # print("DEBUG: conteÃºdo bruto de consolidated_data:\n")
        # print(repr(consolidated_data[:1000]))

        # Mostra os primeiros 500 caracteres
    except Exception as e:
        # Log de erro
        print(f"âŒ Erro na extraÃ§Ã£o estruturada OpenAI: {e}")


        # Salva resultado estruturado
    if logger:
        logger.end_phase('TEXT_PROC', True)
        logger.start_phase('FILE_SAVE', "Salvando anÃ¡lise estruturada")
        
    with open(output_path, "w", encoding="utf-8") as f:
            f.write("".join(results))
        
    with open(output_txt, "w", encoding="utf-8") as f:
        f.write("".join(results_consolidador_json))
        
    with open(output_JSON, "w", encoding="utf-8") as f:
        f.write("".join(results_consolidador_json))

    #salvar_json_removendo_cabecalho_rodape(results_consolidador_json, output_JSON, logger)

    if logger:
            file_size = os.path.getsize(output_path)
            file_size_txt = os.path.getsize(output_txt)
            file_size_json = os.path.getsize(output_JSON)
            logger.log_file_operation("save", output_path, True, file_size)
            logger.log_file_operation("save", output_txt, True, file_size_txt)
            logger.log_file_operation("save", output_JSON, True, file_size_json)
            logger.end_phase('FILE_SAVE', True)
            

    else:
        print(f"âœ… OpenAI Vision Estruturado: Resultado salvo em {output_path}")
        print(f"âœ… OpenAI Vision Estruturado: Resultado TXT salvo em {output_txt}")
        print(f"âœ… OpenAI Vision Estruturado: Resultado JSON salvo em {output_JSON}")
    return True

# Sistema multiprojeto com logs detalhados
if __name__ == "__main__":
    import glob
    import time
    import shutil
    
    # ConfiguraÃ§Ã£o inicial
    current_project = os.environ.get('CURRENT_PROJECT', None)
    pdf_base_path = os.environ.get('PDF_BASE_PATH', None)
    results_base_path = os.environ.get('RESULTS_BASE_PATH', '../resultados')
    
    
    print(f"PDF_BASE_PATH (environ): {repr(os.environ.get('PDF_BASE_PATH'))}")
    print(f"pdf_base_path: {repr(pdf_base_path)}")
    print(f"exists: {os.path.exists(pdf_base_path)}")
    print(f"isdir: {os.path.isdir(pdf_base_path)}")
    print(f"Access OK: {os.access(pdf_base_path, os.R_OK)}")

    # Inicializa sistema de logging
    if current_project:
        logger = get_logger(current_project)
    else:
        logger = get_logger("batch_processing")
    
    logger.start_phase('INIT', "ConfiguraÃ§Ã£o inicial do sistema")
    logger.phases['INIT'].info(f"ðŸ“‚ Pasta PDFs: {pdf_base_path}")
    logger.phases['INIT'].info(f"ðŸ’¾ Pasta resultados: {results_base_path}")
    
    """# Verifica se a pasta base de PDFs existe
    if not os.path.exists(pdf_base_path):
        # Tenta encontrar caminhos alternativos
        alternative_paths = [
            "../../pdfs",
            "../../../pdfs", 
            "../pdfs",
            "pdfs"
        ]
        
        logger.phases['INIT'].info("ðŸ” Tentando localizar pasta base de PDFs...")
        for alt_path in alternative_paths:
            if os.path.exists(alt_path):
                pdf_base_path = alt_path
                logger.phases['INIT'].info(f"âœ… Encontrada em: {alt_path}")
                break
        else:
            logger.phases['INIT'].error("âŒ Nenhuma pasta de PDFs encontrada")
            logger.phases['INIT'].info("ðŸ“ Caminhos testados:")
            for path in alternative_paths:
                logger.phases['INIT'].info(f"   - {path}")
            logger.end_phase('INIT', False)
            exit(1)"""
    
    logger.end_phase('INIT', True)
    logger.start_phase('PDF_SCAN', "Escaneando pastas de PDFs")
    
    # Se CURRENT_PROJECT estÃ¡ definido, processa apenas essa pasta
    if current_project:
        project_dirs = [current_project] if os.path.exists(f"{pdf_base_path}/{current_project}") else []
        if not project_dirs:
            logger.phases['PDF_SCAN'].error(f"âŒ Pasta do projeto {current_project} nÃ£o encontrada")
            logger.end_phase('PDF_SCAN', False)
            exit(1)
        logger.phases['PDF_SCAN'].info(f"ðŸŽ¯ MODO PROJETO ESPECÃFICO: Processando apenas {current_project}")
    else:
        # MODO BATCH: Processa TODAS as pastas de projetos (exceto Processados) atÃ© finalizar
        logger.phases['PDF_SCAN'].info(f"ðŸš€ MODO BATCH COMPLETO: Processando todas as pastas atÃ© finalizar")
        
        # FunÃ§Ã£o para descobrir pastas pendentes
        def get_pending_projects():
            pending = []
            try:
                for item in os.listdir(pdf_base_path):
                    item_path = os.path.join(pdf_base_path, item)
                    if os.path.isdir(item_path) and item.lower() != 'processados':
                        # Verifica se a pasta contÃ©m PDFs
                        pdf_files_in_dir = glob.glob(f"{item_path}/*.pdf")
                        if pdf_files_in_dir:
                            pending.append(item)
            except OSError as e:
                logger.phases['PDF_SCAN'].error(f"âŒ Erro ao escanear pastas: {e}")
            return sorted(pending)
        
        # Descobre todas as pastas pendentes
        project_dirs = get_pending_projects()
        
        if not project_dirs:
            logger.phases['PDF_SCAN'].info(f"âœ… TODAS AS PASTAS JÃ FORAM PROCESSADAS!")
            logger.phases['PDF_SCAN'].info(f"ðŸ“ NÃ£o hÃ¡ novos projetos para processar em {pdf_base_path}")
            logger.end_phase('PDF_SCAN', True)
            
            # Mostra estatÃ­sticas da pasta Processados
            processados_path = f"{pdf_base_path}/Processados"
            if os.path.exists(processados_path):
                processed_folders = [f for f in os.listdir(processados_path) 
                                   if os.path.isdir(os.path.join(processados_path, f))]
                logger.phases['PDF_SCAN'].info(f"ðŸ“Š Total de projetos jÃ¡ processados: {len(processed_folders)}")
                for folder in sorted(processed_folders)[:10]:  # Mostra atÃ© 10
                    logger.phases['PDF_SCAN'].info(f"   âœ… {folder}")
                if len(processed_folders) > 10:
                    logger.phases['PDF_SCAN'].info(f"   ... e mais {len(processed_folders) - 10} projetos")
            exit(0)
    
    logger.phases['PDF_SCAN'].info(f"ðŸ“‚ PASTAS DE PROJETOS ENCONTRADAS: {len(project_dirs)}")
    for i, project_dir in enumerate(project_dirs, 1):
        pdf_count = len(glob.glob(f"{pdf_base_path}/{project_dir}/*.pdf"))
        logger.phases['PDF_SCAN'].info(f"   {i:2d}. {project_dir} ({pdf_count} PDFs)")
    
    logger.end_phase('PDF_SCAN', True)
    
    # EstatÃ­sticas globais
    global_start_time = time.time()
    global_success_count = 0
    global_error_count = 0
    projects_processed = 0
    projects_moved = 0
    
    # Cria pasta de processados se nÃ£o existir
    processados_dir = f"{pdf_base_path}/Processados"
    os.makedirs(processados_dir, exist_ok=True)
    
    # Processa cada projeto
    for project_index, project_name in enumerate(project_dirs, 1):
        logger.logger.info("="*100)
        logger.logger.info(f"ðŸš€ PROCESSANDO PROJETO [{project_index}/{len(project_dirs)}]: {project_name}")
        logger.logger.info("="*100)
        
        project_pdf_path = f"{pdf_base_path}/{project_name}"
        pdf_files = glob.glob(f"{project_pdf_path}/*.pdf")
        
        if not pdf_files:
            logger.logger.warning(f"âš ï¸ Nenhum PDF encontrado em {project_name}, pulando...")
            continue
        
        logger.logger.info(f"ðŸ“„ PDFs encontrados em {project_name}: {len(pdf_files)}")
        for i, pdf_file in enumerate(pdf_files, 1):
            file_size = os.path.getsize(pdf_file) / 1024  # KB
            logger.logger.info(f"   {i:2d}. {os.path.basename(pdf_file)} ({file_size:.1f} KB)")
        
        # Cria diretÃ³rio de resultados para o projeto
        project_output_dir = f"{results_base_path}/{project_name}"
        os.makedirs(project_output_dir, exist_ok=True)
        logger.logger.info(f"ðŸ“ DiretÃ³rio de resultados: {project_output_dir}")
        
        # EstatÃ­sticas do projeto
        project_start_time = time.time()
        project_success_count = 0
        project_error_count = 0
        file_stats = []
        
        # Processa cada PDF do projeto
        for i, pdf_file in enumerate(pdf_files, 1):
            filename = os.path.splitext(os.path.basename(pdf_file))[0]
            
            logger.logger.info("â”€" * 80)
            logger.logger.info(f"ðŸ“„ PROCESSANDO PDF [{i}/{len(pdf_files)}]: {filename}")
            logger.logger.info(f"ðŸ“‚ Arquivo: {pdf_file}")
            logger.logger.info("â”€" * 80)
            
            pdf_dir = f"{project_output_dir}/{filename}"
            os.makedirs(pdf_dir, exist_ok=True)
            logger.logger.info(f"ðŸ“ Pasta de saÃ­da: {pdf_dir}")
            
            file_start_time = time.time()
            file_success = 0
            file_errors = 0
            
            # ExtraÃ§Ã£o bÃ¡sica OpenAI Vision
            txt_output = f"{pdf_dir}/openai_vision_{filename}.txt"
            json_output_txt = f"{pdf_dir}/openai_json_{filename}.txt"
            json_output = f"{pdf_dir}/openai_vision_{filename}.json"
            
            logger.logger.info(f"ðŸ¤– [1/2] EXTRAÃ‡ÃƒO BÃSICA OpenAI Vision...")
            logger.logger.info(f"ðŸ’¾ SaÃ­da: {txt_output}")

            if extract_text_openai_vision(pdf_file, txt_output, json_output_txt, json_output, logger=logger):
                logger.logger.info(f"âœ… ExtraÃ§Ã£o bÃ¡sica concluÃ­da")
                project_success_count += 1
                global_success_count += 1
                file_success += 1
            else:
                logger.logger.error(f"âŒ Falha na extraÃ§Ã£o bÃ¡sica")
                project_error_count += 1
                global_error_count += 1
                file_errors += 1
            

            """# ExtraÃ§Ã£o estruturada OpenAI Vision
            structured_output = f"{pdf_dir}/openai_structured_{filename}.txt"
            structured_output_txt = f"{pdf_dir}/openai_JSON_{filename}.txt"
            structured_output_JSON = f"{pdf_dir}/openai_JSON_{filename}.json"
            logger.logger.info(f"ðŸ§  [2/2] ANÃLISE ESTRUTURADA OpenAI Vision...")
            logger.logger.info(f"ðŸ’¾ SaÃ­da: {structured_output}")

            if extract_structured_openai_vision(pdf_file, structured_output, structured_output_txt, structured_output_JSON, logger=logger):
                logger.logger.info(f"âœ… AnÃ¡lise estruturada concluÃ­da")
                project_success_count += 1
                global_success_count += 1
                file_success += 1
            else:
                logger.logger.error(f"âŒ Falha na anÃ¡lise estruturada")
                project_error_count += 1
                global_error_count += 1
                file_errors += 1
            """

            file_elapsed = time.time() - file_start_time
            logger.logger.info(f"â±ï¸ Tempo para {filename}: {file_elapsed:.2f}s")
            
            # Coleta estatÃ­sticas do arquivo
            file_stat = {
                'filename': filename,
                'time': file_elapsed,
                'success': file_success,
                'errors': file_errors,
                'basic_size': 0,
                'structured_size': 0
            }
            
            # Verifica tamanhos dos arquivos gerados
            if os.path.exists(txt_output):
                size = os.path.getsize(txt_output)
                file_stat['basic_size'] = size
                logger.logger.info(f"ðŸ“Š ExtraÃ§Ã£o bÃ¡sica: {size} bytes")
            
            """if os.path.exists(structured_output):
                size = os.path.getsize(structured_output)
                file_stat['structured_size'] = size
                logger.logger.info(f"ðŸ“Š AnÃ¡lise estruturada: {size} bytes")
            """

            file_stats.append(file_stat)
        
        # RelatÃ³rio do projeto
        project_elapsed = time.time() - project_start_time
        # The above code is attempting to access the `logger` module and then access the `logger`
        # attribute within that module. However, the code is incorrect as it is missing the necessary
        # import statement for the `logger` module. To use the `logger` module, you need to import it
        # first. Here is an example of how you can import and use the `logger` module:
        logger.logger.info("="*80)
        logger.logger.info(f"ðŸ“‹ RELATÃ“RIO DO PROJETO: {project_name}")
        logger.logger.info("="*80)
        logger.logger.info(f"ðŸ“„ PDFs processados: {len(pdf_files)}")
        logger.logger.info(f"âœ… ExtraÃ§Ãµes bem-sucedidas: {project_success_count}")
        logger.logger.info(f"âŒ ExtraÃ§Ãµes com erro: {project_error_count}")
        logger.logger.info(f"â±ï¸ Tempo total do projeto: {project_elapsed:.2f}s")
        if len(pdf_files) > 0:
            logger.logger.info(f"âš¡ Tempo mÃ©dio por PDF: {project_elapsed/len(pdf_files):.2f}s")
        
        # Move projeto para pasta Processados
        logger.logger.info("ðŸ“¦ MOVENDO PROJETO PARA PROCESSADOS...")
        try:
            # Destino principal do projeto
            processados_project_dir = f"{processados_dir}/{project_name}"
            
            # Remove se jÃ¡ existir
            if os.path.exists(processados_project_dir):
                shutil.rmtree(processados_project_dir)
            
            # Move pasta de PDFs para Processados
            shutil.move(project_pdf_path, processados_project_dir)
            logger.logger.info(f"âœ… PDFs movidos para: {processados_project_dir}")
            
            # Move pasta de resultados DENTRO da pasta do projeto
            processados_results_dir = f"{processados_project_dir}/resultados"
            shutil.move(project_output_dir, processados_results_dir)
            logger.logger.info(f"âœ… Resultados movidos para: {processados_results_dir}")
            
            projects_moved += 1
            logger.logger.info(f"ðŸŽ¯ Projeto {project_name} processado e organizado com sucesso!")
            logger.logger.info(f"ðŸ“ Estrutura final: {processados_project_dir}/")
            logger.logger.info(f"   â”œâ”€â”€ PDFs originais")
            logger.logger.info(f"   â””â”€â”€ resultados/ (extraÃ§Ãµes)")
            
        except Exception as e:
            logger.logger.error(f"âŒ Erro ao mover projeto {project_name}: {e}")
            logger.logger.info(f"âš ï¸ Projeto processado mas nÃ£o foi movido")
        
        projects_processed += 1
        logger.logger.info(f"ðŸ“Š Progresso geral: {projects_processed}/{len(project_dirs)} projetos processados")
    
    # RelatÃ³rio final global
    logger.start_phase('STATS', "Compilando estatÃ­sticas finais globais")
    
    global_elapsed = time.time() - global_start_time
    
    # Prepara estatÃ­sticas detalhadas
    stats = {
        'Projetos processados': projects_processed,
        'Projetos movidos': projects_moved,
        'Total de extraÃ§Ãµes bem-sucedidas': global_success_count,
        'Total de extraÃ§Ãµes com erro': global_error_count,
        'Tempo total de execuÃ§Ã£o': f"{global_elapsed:.2f}s",
        'Tempo mÃ©dio por projeto': f"{global_elapsed/projects_processed:.2f}s" if projects_processed > 0 else "N/A",
        'ConcluÃ­do em': datetime.now().strftime('%d/%m/%Y %H:%M:%S')
    }
    
    if global_success_count > 0:
        success_rate = (global_success_count / (global_success_count + global_error_count)) * 100
        stats['Taxa de sucesso global'] = f"{success_rate:.1f}%"
    
    # Log das estatÃ­sticas
    logger.log_statistics(stats)
    
    logger.end_phase('STATS', True)
    
    # Log final com detalhamento de projetos pendentes
    total_runtime = logger.get_total_runtime()
    logger.logger.info("="*100)
    logger.logger.info(f"ðŸŽ‰ PROCESSAMENTO GLOBAL FINALIZADO!")
    logger.logger.info(f"ðŸ“Š Projetos processados nesta execuÃ§Ã£o: {projects_processed}")
    logger.logger.info(f"ðŸ“¦ Projetos movidos para Processados: {projects_moved}")
    logger.logger.info(f"ðŸ“ Pasta Processados: {processados_dir}")
    logger.logger.info(f"â±ï¸ Tempo total de execuÃ§Ã£o: {total_runtime:.2f}s")
    logger.logger.info(f"ðŸ“Š Taxa de sucesso final: {stats.get('Taxa de sucesso global', 'N/A')}")
    
    # Verifica se ainda hÃ¡ pastas pendentes para processar
    try:
        remaining_projects = []
        for item in os.listdir(pdf_base_path):
            item_path = os.path.join(pdf_base_path, item)
            if os.path.isdir(item_path) and item.lower() != 'processados':
                pdf_files_in_dir = glob.glob(f"{item_path}/*.pdf")
                if pdf_files_in_dir:
                    remaining_projects.append(item)
        
        if remaining_projects:
            logger.logger.info("="*100)
            logger.logger.info(f"âš ï¸ AINDA HÃ {len(remaining_projects)} PROJETO(S) PENDENTE(S):")
            for project in sorted(remaining_projects)[:5]:
                pdf_count = len(glob.glob(f"{pdf_base_path}/{project}/*.pdf"))
                logger.logger.info(f"   ðŸ“ {project} ({pdf_count} PDFs)")
            if len(remaining_projects) > 5:
                logger.logger.info(f"   ... e mais {len(remaining_projects) - 5} projetos")
            logger.logger.info(f"ðŸ’¡ Execute novamente para continuar o processamento!")
        else:
            logger.logger.info("="*100)
            logger.logger.info("âœ… TODOS OS PROJETOS FORAM PROCESSADOS!")
            logger.logger.info("ðŸŽ¯ NÃ£o hÃ¡ mais pastas pendentes para processar.")
            
            # Mostra estatÃ­sticas finais da pasta Processados
            if os.path.exists(processados_dir):
                all_processed = [f for f in os.listdir(processados_dir) 
                               if os.path.isdir(os.path.join(processados_dir, f))]
                logger.logger.info(f"ðŸ“Š Total geral de projetos processados: {len(all_processed)}")
                
    except Exception as e:
        logger.logger.warning(f"âš ï¸ Erro ao verificar projetos pendentes: {e}")
    
    logger.logger.info("="*100)
